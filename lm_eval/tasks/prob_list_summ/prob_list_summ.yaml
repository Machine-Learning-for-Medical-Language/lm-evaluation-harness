task: prob_list_summ
dataset_path: med-llm-leaderboard/summ
dataset_name: null
output_type: multiple_choice
test_split: test
doc_to_text: !function pre_process_summ.process_summ
doc_to_target: correct_choice
doc_to_choice: ["A", "B", "C", "D"]
metric_list:
  - metric: acc
    aggregation: mean
    higher_is_better: true
metadata:
  - version: 0.0
